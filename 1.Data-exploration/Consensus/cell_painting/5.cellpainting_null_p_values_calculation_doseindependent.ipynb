{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Null Distribution\n",
    "\n",
    "Gregory Way, modified from code written by Adeniyi Adeboye\n",
    "\n",
    "- Null distribution - is generated by getting the median correlation score of randomly combined compounds that do not share/come from the same MOAs.\n",
    "\n",
    "### The goal here:\n",
    "\n",
    "- is to compute the p-value for each MOA per dose by evaluating the probability of random combinations of compounds (from different MOAs) having greater median correlation score than compounds of the same MOA.\n",
    "- In our case, we generated 1000 median correlation scores from randomly combined compounds as the **null distribution** for each MOA_SIZE class ***i.e. for a moa_size class - we have 1000 medians scores from randomly combined compounds of different MOAs.***\n",
    "- Moa_size is the number of compounds in a specific MOA and moa_size class is a specific group of MOAs that have the same number of compounds ***e.g all MOAs with just 2 compounds in them are in the same moa_size class.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from pycytominer import feature_select\n",
    "from statistics import median\n",
    "import random\n",
    "sns.set_style(\"darkgrid\")\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Load in the datasets required, \n",
    "\n",
    "- They were generated from the `cell_painting_moa_median_scores_calculation notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_moa = pd.read_csv(os.path.join('moa_sizes_consensus_datasets', 'modz_consensus_data.csv'))\n",
    "data_moa_vals = pd.read_csv(os.path.join('moa_sizes_consensus_datasets', 'matching_score_per_MOA_CellPainting_dose_independent.tsv.gz'), sep=\"\\t\")\n",
    "data_moa_cpds = pd.read_csv(os.path.join('moa_sizes_consensus_datasets', 'cellpainting_moa_compounds.csv'))\n",
    "data_moa_cpd_summary = pd.read_csv(os.path.join('moa_sizes_consensus_datasets', 'cellpainting_moa_compounds_dose_independent.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8322, 1032)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_moa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_moa_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_moa_cpds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpd_agg(data_moa, dose_number):\n",
    "    \"\"\"\n",
    "    This function calculates the mean value of distinct compounds\n",
    "    \"\"\"\n",
    "    \n",
    "    df_dose = data_moa[data_moa['Metadata_dose_recode'] == dose_number].copy()\n",
    "    meta_cols = [col for col in df_dose.columns.tolist() \n",
    "                 if (col.startswith(\"Metadata_\"))]\n",
    "    df_dose.drop(meta_cols, axis = 1, inplace = True)\n",
    "    df_compound_agg = df_dose.groupby(['pert_iname']).agg(['mean'])\n",
    "    df_compound_agg.columns  = df_compound_agg.columns.droplevel(1)\n",
    "    df_compound_agg.rename_axis(None, axis=0, inplace = True)\n",
    "    \n",
    "    return df_compound_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpds_found_in_all_doses(data_moa):\n",
    "    \"\"\"This function return a list of compounds found in all doses (1 - 6)\"\"\"\n",
    "    cpds_fd = []\n",
    "    for num in range(1,7):\n",
    "        df_cpd_agg = get_cpd_agg(data_moa, num)\n",
    "        all_cpds = df_cpd_agg.index.tolist()\n",
    "        cpds_fd.append(all_cpds)\n",
    "    \n",
    "    cpds_fd_in_all = [cpd for list_cpds in cpds_fd \n",
    "                      for cpd in list_cpds \n",
    "                      if all(cpd in list_of_cpds for list_of_cpds in cpds_fd)]\n",
    "    cpds_fd_in_all = list(set(cpds_fd_in_all))\n",
    "    \n",
    "    return cpds_fd_in_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the same compounds as previous calculations\n",
    "cpds_fd_in_all = cpds_found_in_all_doses(data_moa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cpds_fd_in_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_moa_list = data_moa['moa'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_moa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_moa_dict = {moa: [cpd for cpd in data_moa['pert_iname'][data_moa['moa']== moa].unique().tolist() \n",
    "                      if cpd in cpds_fd_in_all]\n",
    "                for moa in all_moa_list}\n",
    "all_moa_dict = {kys:all_moa_dict[kys] for kys in all_moa_dict if all_moa_dict[kys]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_moa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_moa_vals.moa.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_moa_cpds = data_moa_cpds.drop(columns=[\"moa_size\"]).merge(data_moa_vals, on=\"moa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_moa_size_dict(df_moa_cpds):\n",
    "    \"\"\"\n",
    "    Generates a dictionary with distinct moa_sizes \n",
    "    (moa_size == number of compounds that is present in each MOA) \n",
    "    as the keys and all compounds of MOAs with that particular size as the values\n",
    "    \"\"\"\n",
    "    moa_size_dict = {}\n",
    "    for size in df_moa_cpds['no_of_replicates'].unique():\n",
    "        size_df = df_moa_cpds[df_moa_cpds['no_of_replicates'] == size].drop(['no_of_replicates', 'moa', 'spearman_correlation'], axis = 1)\n",
    "        size_df_values = size_df.values.tolist()\n",
    "        size_df_values = [x.split(\";\") for cpd_list in size_df_values for x in cpd_list]\n",
    "        size_df_values = list(set([x for cpd in size_df_values for x in cpd]))\n",
    "        moa_size_dict[size] = size_df_values\n",
    "    return moa_size_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_sizes_dict = generate_moa_size_dict(data_moa_cpds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_moa_cpds['no_of_replicates'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moa_sizes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_cpds(all_cpds, moa_size, moa_cpds, all_moa_cpds):\n",
    "    \"\"\"\n",
    "    This function return a list of random cpds that are not of the same moas \n",
    "    or found in the current moa cpd's list\n",
    "    \"\"\"\n",
    "    while (True):\n",
    "        random_cpds = random.sample(all_cpds, moa_size)\n",
    "        if not (any(cpds in moa_cpds for cpds in random_cpds)):\n",
    "            break\n",
    "    return random_cpds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - You only need to generate the null distribution once (i.e. you can re-use the pickled null distribution for other consensus data), since the 1000 lists of randomly generated compounds combinations  for each MOA are found in all doses and all consensus datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_distribution_cpds(moa_size_dict, cpds_list, all_moa_dict, rand_num = 1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns the null distribution dictionary, with MOAs as the keys and \n",
    "    1000 lists of randomly selected compounds combinations as the values for each MOA\n",
    "    \"\"\"\n",
    "    null_distribution_moa = {}\n",
    "    for size in moa_size_dict:\n",
    "        print(size)\n",
    "        moa_cpds = moa_size_dict[size]\n",
    "        moa_cpds_list = []\n",
    "        for idx in range(rand_num):\n",
    "            start_again = True\n",
    "            while (start_again):\n",
    "                rand_cpds = get_random_cpds(cpds_list, size, moa_cpds, all_moa_dict)\n",
    "                if rand_cpds not in moa_cpds_list:\n",
    "                    start_again = False\n",
    "            moa_cpds_list.append(rand_cpds)\n",
    "        null_distribution_moa[size] = moa_cpds_list\n",
    "    \n",
    "    return null_distribution_moa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "18\n",
      "48\n",
      "120\n",
      "24\n",
      "180\n",
      "30\n",
      "6\n",
      "84\n",
      "66\n",
      "90\n",
      "42\n",
      "150\n",
      "54\n",
      "108\n",
      "72\n",
      "36\n",
      "78\n",
      "138\n",
      "168\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "null_distribution_moa = get_null_distribution_cpds(moa_sizes_dict, cpds_fd_in_all, all_moa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the null_distribution_moa to pickle, you only need to run the code once\n",
    "with open(os.path.join('moa_sizes_consensus_datasets', 'null_distribution_doseindependent.pickle'), 'wb') as handle:\n",
    "    pickle.dump(null_distribution_moa, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the null_distribution_moa from pickle\n",
    "with open(os.path.join('moa_sizes_consensus_datasets', 'null_distribution_doseindependent.pickle'), 'rb') as handle:\n",
    "    null_distribution_moa = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moa_size \tnumber of generated lists of randomly combined compounds\n",
      "12 \t\t 1000\n",
      "18 \t\t 1000\n",
      "48 \t\t 1000\n",
      "120 \t\t 1000\n",
      "24 \t\t 1000\n",
      "180 \t\t 1000\n",
      "30 \t\t 1000\n",
      "6 \t\t 1000\n",
      "84 \t\t 1000\n",
      "66 \t\t 1000\n",
      "90 \t\t 1000\n",
      "42 \t\t 1000\n",
      "150 \t\t 1000\n",
      "54 \t\t 1000\n",
      "108 \t\t 1000\n",
      "72 \t\t 1000\n",
      "36 \t\t 1000\n",
      "78 \t\t 1000\n",
      "138 \t\t 1000\n",
      "168 \t\t 1000\n",
      "60 \t\t 1000\n"
     ]
    }
   ],
   "source": [
    "print('moa_size', '\\tnumber of generated lists of randomly combined compounds')\n",
    "for keys in null_distribution_moa:\n",
    "    print(keys, '\\t\\t', len(null_distribution_moa[keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_null_distribution(null_distribution_moa):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function assert that each of the list in the 1000 lists of \n",
    "    random compounds combination for each MOA are distinct with no duplicates\n",
    "    \"\"\"\n",
    "    \n",
    "    duplicates_moa = {}\n",
    "    for keys in null_distribution_moa:\n",
    "        null_dist = null_distribution_moa[keys]\n",
    "        for cpds_moa in null_dist:\n",
    "            cpds_duplicates = []\n",
    "            new_list = list(filter(lambda cpds_list: cpds_list != cpds_moa, null_dist))\n",
    "            if (len(new_list) != len(null_dist) - 1):\n",
    "                cpds_duplicates.append(cpds_moa)\n",
    "        if cpds_duplicates:\n",
    "            duplicates_moa[keys] = cpds_duplicates\n",
    "    return duplicates_moa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_cpds_list = assert_null_distribution(null_distribution_moa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_cpds_list ##no duplicate found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpd_agg_dose_independent(data_moa):\n",
    "    \"\"\"\n",
    "    This function calculates the mean value of distinct compounds\n",
    "    \"\"\"\n",
    "    \n",
    "    df = data_moa.copy()\n",
    "\n",
    "    df_cpd_agg = df.groupby(['pert_iname', 'Metadata_dose_recode']).agg(['mean']).reset_index()\n",
    "    df_cpd_agg.index = df_cpd_agg.pert_iname\n",
    "    \n",
    "    meta_cols = ['pert_iname', \"Metadata_dose_recode\", \"Metadata_mmoles_per_liter\"]\n",
    "        \n",
    "    df_cpd_agg.drop(meta_cols, axis = 1, inplace = True)\n",
    "    \n",
    "    return df_cpd_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_null_dist_median_scores(data_moa, moa_cpds_list):\n",
    "    \"\"\"\n",
    "    This function calculate the median of the correlation \n",
    "    values for each of the list in the 1000 lists of \n",
    "    random compounds combination for each MOA\n",
    "    \"\"\"\n",
    "    df_cpd_agg = get_cpd_agg_dose_independent(data_moa)\n",
    "    median_corr_list = []\n",
    "    for list_of_cpds in moa_cpds_list:\n",
    "        df_cpds = df_cpd_agg.loc[list_of_cpds]\n",
    "        cpds_corr = df_cpds.transpose().corr(method='spearman')\n",
    "        \n",
    "        if len(list_of_cpds) == 1:\n",
    "            median_corr_val = 1\n",
    "        else:\n",
    "            cpds_corr.index.name = \"pert_iname_compare\"\n",
    "            cpds_corr = cpds_corr.reset_index().melt(id_vars = \"pert_iname_compare\", value_name=\"spearman_corr\")\n",
    "            cpds_corr = cpds_corr.assign(keep_me_diff_comparison = cpds_corr.pert_iname_compare != cpds_corr.pert_iname)\n",
    "            cpds_corr = cpds_corr.query(\"keep_me_diff_comparison\")\n",
    "            median_corr_val = cpds_corr.spearman_corr.median()\n",
    "\n",
    "        median_corr_list.append(median_corr_val)\n",
    "    return median_corr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A P value can be computed nonparametrically by evaluating the probability of random compounds of different MOAs having greater median similarity value than compounds of the same MOAs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(median_scores_list, df_moa_values, moa_name):\n",
    "    \"\"\"\n",
    "    This function calculate the p-value from the \n",
    "    null_distribution median scores for each MOA\n",
    "    \"\"\"\n",
    "    actual_med = df_moa_values.loc[moa_name, :]\n",
    "    p_value = np.sum(median_scores_list >= actual_med) / len(median_scores_list)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_dist_median_scores(null_distribution_moa, df_moa):\n",
    "    \"\"\" \n",
    "    This function calculate the median correlation scores for all \n",
    "    1000 lists of randomly combined compounds for each moa_size class \n",
    "    \"\"\"\n",
    "    null_distribution_medians = {}\n",
    "    for key in null_distribution_moa:\n",
    "        null_distribution_medians[key] = calc_null_dist_median_scores(df_moa, null_distribution_moa[key])\n",
    "    return null_distribution_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/gway/miniconda3/envs/lincs-complimentarity/lib/python3.9/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "null_distribution_medns = get_null_dist_median_scores(null_distribution_moa, data_moa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(rep, rep_name):\n",
    "    \"\"\"\n",
    "    Transforms replicate correlation dataframe to have 3 columns: \n",
    "    dose, correlation_values and type of replicates\n",
    "    \"\"\"\n",
    "    df_reps = pd.DataFrame.from_dict(rep, orient='index').T\n",
    "    rep_melt = df_reps.melt(var_name=\"dose\", value_name=\"correlation_values\")\n",
    "    rep_melt['type'] = rep_name\n",
    "    return rep_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_replicates</th>\n",
       "      <th>dose</th>\n",
       "      <th>95th_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.012974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.010977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.008786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.007790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.010778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.007625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.018276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.007934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.008390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.008050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.009280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.007544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>54</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.008757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>108</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.007931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.008179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.009211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>78</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.008124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>138</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.007741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>168</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.007448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>60</td>\n",
       "      <td>all_doses</td>\n",
       "      <td>0.008599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_replicates       dose  95th_threshold\n",
       "0             12  all_doses        0.012974\n",
       "1             18  all_doses        0.010977\n",
       "2             48  all_doses        0.008786\n",
       "3            120  all_doses        0.007790\n",
       "4             24  all_doses        0.010778\n",
       "5            180  all_doses        0.007625\n",
       "6             30  all_doses        0.009852\n",
       "7              6  all_doses        0.018276\n",
       "8             84  all_doses        0.007934\n",
       "9             66  all_doses        0.008390\n",
       "10            90  all_doses        0.008050\n",
       "11            42  all_doses        0.009280\n",
       "12           150  all_doses        0.007544\n",
       "13            54  all_doses        0.008757\n",
       "14           108  all_doses        0.007931\n",
       "15            72  all_doses        0.008179\n",
       "16            36  all_doses        0.009211\n",
       "17            78  all_doses        0.008124\n",
       "18           138  all_doses        0.007741\n",
       "19           168  all_doses        0.007448\n",
       "20            60  all_doses        0.008599"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_df = []\n",
    "for n_replicate in null_distribution_medns.keys():\n",
    "    matched_null = pd.DataFrame(null_distribution_medns[n_replicate])\n",
    "    thresh = matched_null.quantile(0.95).values[0]\n",
    "    threshold_df.append([n_replicate, \"all_doses\", thresh])\n",
    "        \n",
    "threshold_df = pd.DataFrame(threshold_df, columns=[\"n_replicates\", \"dose\", \"95th_threshold\"])\n",
    "threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(median_scores_list, df_moa_values, moa_name):\n",
    "    \"\"\"\n",
    "    This function calculate the p-value from the \n",
    "    null_distribution median scores for each MOA\n",
    "    \"\"\"\n",
    "    actual_med = df_moa_values.loc[moa_name, :].spearman_correlation\n",
    "    p_value = np.sum(median_scores_list >= actual_med) / len(median_scores_list)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moa_p_vals(null_dist_median, df_moa_values):\n",
    "    \"\"\"\n",
    "    This function returns a dict, with MOAs as the keys and the MOA's p-values as the values\n",
    "    \"\"\"\n",
    "    null_p_vals = {}\n",
    "    df_moa_values = df_moa_values.set_index('moa').rename_axis(None, axis=0)\n",
    "    for key in null_dist_median:\n",
    "        df_moa_size = df_moa_values[df_moa_values['no_of_replicates'] == key]\n",
    "        for moa in df_moa_size.index:\n",
    "            moa_p_value = get_p_value(null_dist_median[key], df_moa_size, moa)\n",
    "            null_p_vals[moa] = moa_p_value\n",
    "    sorted_null_p_vals = {key:value for key, value in sorted(null_p_vals.items(), key=lambda item: item[0])}\n",
    "    return sorted_null_p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_p_vals = get_moa_p_vals(null_distribution_medns, data_moa_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_p_vals = pd.DataFrame.from_dict(null_p_vals, orient='index', \n",
    "                                        columns = [\"p_value_alldose\"]).reset_index().rename(columns={\"index\": \"moa\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_p_vals = (\n",
    "    df_null_p_vals\n",
    "    .merge(data_moa_vals, on=\"moa\")\n",
    "    .drop(columns=[\"spearman_correlation\"])\n",
    "    .rename(columns={\"no_of_replicates\": \"moa_size\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null_p_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moa</th>\n",
       "      <th>p_value_alldose</th>\n",
       "      <th>moa_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 alpha reductase inhibitor</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acat inhibitor</td>\n",
       "      <td>0.988</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acetylcholine receptor agonist</td>\n",
       "      <td>1.000</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acetylcholine receptor antagonist</td>\n",
       "      <td>0.177</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acetylcholine release stimulant</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acetylcholinesterase inhibitor</td>\n",
       "      <td>0.929</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adenosine receptor agonist</td>\n",
       "      <td>0.964</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adenosine receptor antagonist</td>\n",
       "      <td>0.331</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adrenergic inhibitor</td>\n",
       "      <td>0.157</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adrenergic receptor agonist</td>\n",
       "      <td>0.984</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 moa  p_value_alldose  moa_size\n",
       "0        5 alpha reductase inhibitor            1.000        12\n",
       "1                     acat inhibitor            0.988        18\n",
       "2     acetylcholine receptor agonist            1.000        48\n",
       "3  acetylcholine receptor antagonist            0.177       120\n",
       "4    acetylcholine release stimulant            1.000        12\n",
       "5     acetylcholinesterase inhibitor            0.929        12\n",
       "6         adenosine receptor agonist            0.964        18\n",
       "7      adenosine receptor antagonist            0.331        24\n",
       "8               adrenergic inhibitor            0.157        12\n",
       "9        adrenergic receptor agonist            0.984       120"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null_p_vals.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, path, file_name):\n",
    "    \"\"\"saves moa dataframes to csv\"\"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    df.to_csv(os.path.join(path, file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(df_null_p_vals, 'moa_sizes_consensus_datasets', 'modz_null_p_values_doseindependent.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
