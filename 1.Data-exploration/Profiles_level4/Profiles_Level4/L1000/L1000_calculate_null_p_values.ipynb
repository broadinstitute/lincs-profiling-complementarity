{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Null Distribution\n",
    "\n",
    "\n",
    "\n",
    "Null distribution - is generated by getting the median correlation score of randomly combined replicates that do not come from the same compounds.\n",
    "\n",
    "\n",
    "\n",
    "### The goal here: \n",
    "\n",
    "-- is to compute the **p-value** for each compound per dose by evaluating the probability of random combinations of replicates (from different compounds) having greater median correlation score than replicates that come from the same compound.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- In our case, we generated 1000 median correlation scores from randomly combined replicates as the **null distribution** for each CPD_SIZE class per DOSE i.e. for a cpd_size class for every DOSE (1-6) - we have 1000 medians scores from randomly combined replicates of different compounds.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Cpd_size is the number of replicates in a specific compound and cpd_size class is a specific group of compounds that have the same amount of replicates e.g all compounds with 3 replicates in them are in the same cpd_size class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from os import walk\n",
    "from collections import Counter\n",
    "import random\n",
    "import shutil\n",
    "from statistics import median\n",
    "import cmapPy.pandasGEXpress.parse_gct as pg\n",
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load in Level 4 Datasets generated from `calculate_median_scores_notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1000_level4_path = \"L1000_lvl4_cpd_replicate_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level4 = pd.read_csv(os.path.join(L1000_level4_path, 'L1000_level4W_cpd_replicates.csv.gz'), \n",
    "                        compression='gzip',low_memory = False)\n",
    "df_cpd_med_scores = pd.read_csv(os.path.join(L1000_level4_path, 'cpd_replicate_median_scores_W.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpd_med_scores = df_cpd_med_scores.set_index('cpd').rename_axis(None, axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cpd_med_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27837, 984)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_level4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpds_replicates(df, df_lvl4):\n",
    "    \"\"\"\n",
    "    This function returns all replicates id/names found in each compound \n",
    "    and in all doses(1-6)\n",
    "    \"\"\"\n",
    "    \n",
    "    dose_list = list(set(df_lvl4['dose'].unique().tolist()))[1:7]\n",
    "    replicates_in_all = []\n",
    "    cpds_replicates = {}\n",
    "    for dose in dose_list:\n",
    "        rep_list = []\n",
    "        df_doses = df_lvl4[df_lvl4['dose'] == dose].copy()\n",
    "        for cpd in df.index:\n",
    "            replicate_names = df_doses[df_doses['pert_iname'] == cpd]['replicate_id'].values.tolist()\n",
    "            rep_list += replicate_names\n",
    "            if cpd not in cpds_replicates:\n",
    "                cpds_replicates[cpd] = [replicate_names]\n",
    "            else:\n",
    "                cpds_replicates[cpd] += [replicate_names]\n",
    "        replicates_in_all.append(rep_list)\n",
    "        \n",
    "    return replicates_in_all, cpds_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicates_in_all, cpds_replicates = get_cpds_replicates(df_cpd_med_scores, df_level4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replicates_per_cpd_size(df, df_lvl4, cpds_replicates):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function gets all replicates ids for each distinct \n",
    "    cpd_size (i.e. number of replicates per cpd) classes\n",
    "    \n",
    "    Returns cpd_size_dict dictionary, with cpd_size as the keys, \n",
    "    and replicate_ids for each cpd_size as the values\n",
    "    \"\"\"\n",
    "    \n",
    "    df['replicate_id'] = list(cpds_replicates.values())\n",
    "    dose_list = list(set(df_lvl4['dose'].unique().tolist()))[1:7]\n",
    "    cpd_size_dict = {}\n",
    "    for dose in dose_list:\n",
    "        for size in df['cpd_size'].unique():\n",
    "            rep_lists = []\n",
    "            for idx in range(df[df['cpd_size'] == size].shape[0]):\n",
    "                rep_ids = df[df['cpd_size'] == size]['replicate_id'].values.tolist()[idx][dose-1]\n",
    "                rep_lists += rep_ids\n",
    "            if size not in cpd_size_dict:\n",
    "                cpd_size_dict[size] = [rep_lists]\n",
    "            else:\n",
    "                cpd_size_dict[size] += [rep_lists]\n",
    "                \n",
    "    return cpd_size_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_size_dict = replicates_per_cpd_size(df_cpd_med_scores, df_level4, cpds_replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similar_replicates(replicates, dose, cpd_dict):\n",
    "    \"\"\"This function checks if two replicates are of the same compounds\"\"\"\n",
    "    \n",
    "    for x in range(len(replicates)):\n",
    "        for y in range(x+1, len(replicates)):\n",
    "            for kys in cpd_dict:\n",
    "                if all(i in cpd_dict[kys][dose-1] for i in [replicates[x], replicates[y]]):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_replicates(all_replicates, cpd_size, dose, replicates_ids, cpd_replicate_dict):\n",
    "    \"\"\"\n",
    "    This function return a list of random replicates that are not of the same compounds\n",
    "    or found in the current cpd's size list\n",
    "    \"\"\"\n",
    "    while (True):\n",
    "        random_replicates = random.sample(all_replicates, cpd_size)\n",
    "        if not (any(rep in replicates_ids for rep in random_replicates) & \n",
    "                (check_similar_replicates(random_replicates, dose, cpd_replicate_dict))):\n",
    "            break\n",
    "    return random_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_distribution_replicates(cpd_size_dict, dose_list, replicates_lists, cpd_replicate_dict, rand_num = 1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns a null distribution dictionary, with CPD_SIZEs as the keys and \n",
    "    1000 lists of randomly selected replicate combinations as the values\n",
    "    for each cpd_size class per DOSE(1-6)\n",
    "    \"\"\"\n",
    "    null_distribution_reps = {}\n",
    "    for dose in dose_list:\n",
    "        for size in cpd_size_dict:\n",
    "            replicates_ids = cpd_size_dict[size][dose-1]\n",
    "            replicate_list = []\n",
    "            for idx in range(rand_num):\n",
    "                start_again = True\n",
    "                while (start_again):\n",
    "                    rand_cpds = get_random_replicates(replicates_lists[dose-1], size, dose, \n",
    "                                                      replicates_ids, cpd_replicate_dict)\n",
    "                    if rand_cpds not in replicate_list:\n",
    "                        start_again = False\n",
    "                replicate_list.append(rand_cpds)\n",
    "            if size not in null_distribution_reps:\n",
    "                null_distribution_reps[size] = [replicate_list]\n",
    "            else:\n",
    "                null_distribution_reps[size] += [replicate_list]\n",
    "    \n",
    "    return null_distribution_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_list = list(set(df_level4['dose'].unique().tolist()))[1:7]\n",
    "null_distribution_replicates = get_null_distribution_replicates(cpd_size_dict, dose_list, replicates_in_all, cpds_replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(null_distribution, path, file_name):\n",
    "    \"\"\"This function saves the null distribution replicates ids into a pickle file\"\"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    with open(os.path.join(path, file_name), 'wb') as handle:\n",
    "        pickle.dump(null_distribution, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(null_distribution_replicates, L1000_level4_path, 'null_distribution_W.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the null_distribution_moa from pickle\n",
    "with open(os.path.join(L1000_level4_path, 'null_distribution_W.pickle'), 'rb') as handle:\n",
    "    null_distribution_replicates = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_null_distribution(null_distribution_reps, dose_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function assert that each of the list in the 1000 lists of \n",
    "    random replicate combination (per dose) for each cpd size are distinct with no duplicates\n",
    "    \"\"\"\n",
    "    \n",
    "    duplicates_reps = {}\n",
    "    for dose in dose_list:\n",
    "        for keys in null_distribution_reps:\n",
    "            null_dist = null_distribution_reps[keys][dose-1]\n",
    "            for reps in null_dist:\n",
    "                dup_reps = []\n",
    "                new_list = list(filter(lambda x: x != reps, null_dist))\n",
    "                if (len(new_list) != len(null_dist) - 1):\n",
    "                    dup_reps.append(reps)\n",
    "            if dup_reps:\n",
    "                if keys not in duplicates_reps:\n",
    "                    duplicates_reps[keys] = [dup_reps]\n",
    "                else:\n",
    "                    duplicates_reps[keys] += [dup_reps]\n",
    "    return duplicates_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_replicates = assert_null_distribution(null_distribution_replicates, dose_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_replicates ##no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_null_dist_median_scores(df, dose_num, replicate_lists):\n",
    "    \"\"\"\n",
    "    This function calculate the median of the correlation \n",
    "    values for each list in the 1000 lists of random replicate \n",
    "    combination for each cpd size per dose\n",
    "    \"\"\"\n",
    "    df_dose = df[df['dose'] == dose_num].copy()\n",
    "    df_dose = df_dose.set_index('replicate_id').rename_axis(None, axis=0)\n",
    "    df_dose.drop(['Metadata_broad_sample', 'pert_id', 'dose', 'pert_idose', \n",
    "                  'pert_iname', 'moa', 'sig_id'], axis = 1, inplace = True)\n",
    "    median_corr_list = []\n",
    "    for rep_list in replicate_lists:\n",
    "        df_reps = df_dose.loc[rep_list].copy()\n",
    "        reps_corr = df_reps.astype('float64').T.corr(method = 'spearman').values\n",
    "        median_corr_val = median(list(reps_corr[np.triu_indices(len(reps_corr), k = 1)]))\n",
    "        median_corr_list.append(median_corr_val)\n",
    "    return median_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_dist_median_scores(null_distribution_cpds, dose_list, df):\n",
    "    \"\"\" \n",
    "    This function calculate the median correlation scores for all \n",
    "    1000 lists of randomly combined compounds for each cpd_size class \n",
    "    across all doses (1-6)\n",
    "    \"\"\"\n",
    "    null_distribution_medians = {}\n",
    "    for key in null_distribution_cpds:\n",
    "        median_score_list = []\n",
    "        for dose in dose_list:\n",
    "            replicate_median_scores = calc_null_dist_median_scores(df, dose, null_distribution_cpds[key][dose-1])\n",
    "            median_score_list.append(replicate_median_scores)\n",
    "        null_distribution_medians[key] = median_score_list\n",
    "    return null_distribution_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distribution_medians = get_null_dist_median_scores(null_distribution_replicates, dose_list, df_level4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A P value can be computed nonparametrically by evaluating the probability of random replicates of different compounds having median similarity value greater than replicates of the same compounds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(median_scores_list, df, dose_name, cpd_name):\n",
    "    \"\"\"\n",
    "    This function calculate the p-value from the \n",
    "    null_distribution median scores for each compound\n",
    "    \"\"\"\n",
    "    actual_med = df.loc[cpd_name, dose_name]\n",
    "    p_value = np.sum(median_scores_list >= actual_med) / len(median_scores_list)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moa_p_vals(null_dist_median, dose_list, df_med_values):\n",
    "    \"\"\"\n",
    "    This function returns a dict, with compounds as the keys and the compound's \n",
    "    p-values for each dose (1-6) as the values\n",
    "    \"\"\"\n",
    "    null_p_vals = {}\n",
    "    for key in null_dist_median:\n",
    "        df_cpd_size = df_med_values[df_med_values['cpd_size'] == key]\n",
    "        for cpd in df_cpd_size.index:\n",
    "            dose_p_values = []\n",
    "            for num in dose_list:\n",
    "                dose_name = 'dose_' + str(num)\n",
    "                cpd_p_value = get_p_value(null_dist_median[key][num-1], df_cpd_size, dose_name, cpd)\n",
    "                dose_p_values.append(cpd_p_value)\n",
    "            null_p_vals[cpd] = dose_p_values\n",
    "    sorted_null_p_vals = {key:value for key, value in sorted(null_p_vals.items(), key=lambda item: item[0])}\n",
    "    return sorted_null_p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_p_vals = get_moa_p_vals(null_distribution_medians, dose_list, df_cpd_med_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_p_vals = pd.DataFrame.from_dict(null_p_vals, orient='index', columns = ['dose_' + str(x) for x in dose_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_p_vals['cpd_size'] = df_cpd_med_scores['cpd_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dose_1</th>\n",
       "      <th>dose_2</th>\n",
       "      <th>dose_3</th>\n",
       "      <th>dose_4</th>\n",
       "      <th>dose_5</th>\n",
       "      <th>dose_6</th>\n",
       "      <th>cpd_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17-hydroxyprogesterone-caproate</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.140</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-iminobiotin</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.584</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-amino-benzamide</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-deazaadenosine</th>\n",
       "      <td>0.207</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.288</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT-737</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AICA-ribonucleotide</th>\n",
       "      <td>0.153</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AKT-inhibitor-1-2</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.553</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALX-5407</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS-605240</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT-7519</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dose_1  dose_2  dose_3  dose_4  dose_5  \\\n",
       "17-hydroxyprogesterone-caproate   0.935   0.105   0.045   0.001   0.013   \n",
       "2-iminobiotin                     0.877   0.012   0.555   0.751   0.099   \n",
       "3-amino-benzamide                 0.014   0.339   0.393   0.509   0.186   \n",
       "3-deazaadenosine                  0.207   0.522   0.341   0.250   0.510   \n",
       "ABT-737                           0.143   0.891   0.110   0.412   0.060   \n",
       "AICA-ribonucleotide               0.153   0.045   0.347   0.011   0.331   \n",
       "AKT-inhibitor-1-2                 0.573   0.039   0.109   0.079   0.501   \n",
       "ALX-5407                          0.030   0.098   0.002   0.081   0.120   \n",
       "AS-605240                         0.980   0.029   0.848   0.808   0.027   \n",
       "AT-7519                           0.005   0.187   0.044   0.000   0.000   \n",
       "\n",
       "                                 dose_6  cpd_size  \n",
       "17-hydroxyprogesterone-caproate   0.140         3  \n",
       "2-iminobiotin                     0.584         2  \n",
       "3-amino-benzamide                 0.011         3  \n",
       "3-deazaadenosine                  0.288         2  \n",
       "ABT-737                           0.003         3  \n",
       "AICA-ribonucleotide               0.033         3  \n",
       "AKT-inhibitor-1-2                 0.553         3  \n",
       "ALX-5407                          0.013         3  \n",
       "AS-605240                         0.066         2  \n",
       "AT-7519                           0.000         3  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null_p_vals.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, path, file_name):\n",
    "    \"\"\"saves dataframes to csv\"\"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    df.to_csv(os.path.join(path, file_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(df_null_p_vals.reset_index().rename({'index':'cpd'}, axis = 1), L1000_level4_path, \n",
    "            'cpd_replicate_p_values_W.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
