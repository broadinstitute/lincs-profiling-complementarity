{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Null Distribution\n",
    "\n",
    "\n",
    "\n",
    "Null distribution - is generated by getting the median correlation score of randomly combined replicates that do not come from the same compounds.\n",
    "\n",
    "\n",
    "\n",
    "### The goal here: \n",
    "\n",
    "-- is to compute the **p-value** for each compound per dose by evaluating the probability of random combinations of replicates (from different compounds) having greater median correlation score than replicates that come from the same compound.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- In our case, we generated 1000 median correlation scores from randomly combined replicates as the **null distribution** for each no_of_replicates/replicate class per DOSE i.e. for a no_of_replicates class for every DOSE (1-6) - we have 1000 medians scores from randomly combined replicates of different compounds.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**no_of_replicate** is the number of replicates in a specific compound and **no_of_replicate class** is a specific group of compounds that have the same amount of replicates e.g all compounds with 3 replicates in them are in the same no_of_replicates class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from os import walk\n",
    "from collections import Counter\n",
    "import random\n",
    "import shutil\n",
    "from statistics import median\n",
    "import cmapPy.pandasGEXpress.parse_gct as pg\n",
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load in Level 4 Datasets generated from `calculate_median_scores_notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1000_level4_path = \"L1000_lvl4_cpd_replicate_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level4 = pd.read_csv(os.path.join(L1000_level4_path, 'L1000_level4W_cpd_replicates.csv.gz'), \n",
    "                        compression='gzip',low_memory = False)\n",
    "df_cpd_med_scores = pd.read_csv(os.path.join(L1000_level4_path, 'cpd_replicate_median_scores_w.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpd_med_scores = df_cpd_med_scores.set_index('cpd').rename_axis(None, axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cpd_med_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27837, 988)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_level4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpds_replicates(df, df_lvl4):\n",
    "    \"\"\"\n",
    "    This function returns all replicates id/names found in each compound \n",
    "    and in all doses(1-6)\n",
    "    \"\"\"\n",
    "    \n",
    "    dose_list = list(set(df_lvl4['dose'].unique().tolist()))[1:7]\n",
    "    replicates_in_all = []\n",
    "    cpds_replicates = {}\n",
    "    for dose in dose_list:\n",
    "        rep_list = []\n",
    "        df_doses = df_lvl4[df_lvl4['dose'] == dose].copy()\n",
    "        for cpd in df.index:\n",
    "            replicate_names = df_doses[df_doses['pert_iname'] == cpd]['replicate_id'].values.tolist()\n",
    "            rep_list += replicate_names\n",
    "            if cpd not in cpds_replicates:\n",
    "                cpds_replicates[cpd] = [replicate_names]\n",
    "            else:\n",
    "                cpds_replicates[cpd] += [replicate_names]\n",
    "        replicates_in_all.append(rep_list)\n",
    "        \n",
    "    return replicates_in_all, cpds_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicates_in_all, cpds_replicates = get_cpds_replicates(df_cpd_med_scores, df_level4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replicates_classes_per_dose(df, df_lvl4, cpds_replicates):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function gets all replicates ids for each distinct \n",
    "    no_of_replicates (i.e. number of replicates per cpd) class per dose (1-6)\n",
    "    \n",
    "    Returns replicate_class_dict dictionary, with no_of_replicate classes as the keys, \n",
    "    and all the replicate_ids for each no_of_replicate class as the values\n",
    "    \"\"\"\n",
    "    \n",
    "    df['replicate_id'] = list(cpds_replicates.values())\n",
    "    dose_list = list(set(df_lvl4['dose'].unique().tolist()))[1:7]\n",
    "    replicate_class_dict = {}\n",
    "    for dose in dose_list:\n",
    "        for size in df['no_of_replicates'].unique():\n",
    "            rep_lists = []\n",
    "            for idx in range(df[df['no_of_replicates'] == size].shape[0]):\n",
    "                rep_ids = df[df['no_of_replicates'] == size]['replicate_id'].values.tolist()[idx][dose-1]\n",
    "                rep_lists += rep_ids\n",
    "            if size not in replicate_class_dict:\n",
    "                replicate_class_dict[size] = [rep_lists]\n",
    "            else:\n",
    "                replicate_class_dict[size] += [rep_lists]\n",
    "                \n",
    "    return replicate_class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_replicate_class_dict = get_replicates_classes_per_dose(df_cpd_med_scores, df_level4, cpds_replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 2, 4, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpd_replicate_class_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similar_replicates(replicates, dose, cpd_dict):\n",
    "    \"\"\"This function checks if two replicates are of the same compounds\"\"\"\n",
    "    \n",
    "    for x in range(len(replicates)):\n",
    "        for y in range(x+1, len(replicates)):\n",
    "            for kys in cpd_dict:\n",
    "                if all(i in cpd_dict[kys][dose-1] for i in [replicates[x], replicates[y]]):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_replicates(all_replicates, no_of_replicates, dose, replicates_ids, cpd_replicate_dict):\n",
    "    \"\"\"\n",
    "    This function return a list of random replicates that are not of the same compounds\n",
    "    or found in the current cpd's size list\n",
    "    \"\"\"\n",
    "    while (True):\n",
    "        random_replicates = random.sample(all_replicates, no_of_replicates)\n",
    "        if not (any(rep in replicates_ids for rep in random_replicates) & \n",
    "                (check_similar_replicates(random_replicates, dose, cpd_replicate_dict))):\n",
    "            break\n",
    "    return random_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_distribution_replicates(cpd_replicate_class_dict, dose_list, replicates_lists, \n",
    "                                     cpd_replicate_dict, rand_num = 1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns a null distribution dictionary, with no_of_replicates(replicate class) \n",
    "    as the keys and 1000 lists of randomly selected replicate combinations as the values\n",
    "    for each no_of_replicates class per DOSE(1-6)\n",
    "    \"\"\"\n",
    "    random.seed(1903)\n",
    "    null_distribution_reps = {}\n",
    "    for dose in dose_list:\n",
    "        for replicate_class in cpd_replicate_class_dict:\n",
    "            replicates_ids = cpd_replicate_class_dict[replicate_class][dose-1]\n",
    "            replicate_list = []\n",
    "            for idx in range(rand_num):\n",
    "                start_again = True\n",
    "                while (start_again):\n",
    "                    rand_cpds = get_random_replicates(replicates_lists[dose-1], replicate_class, dose, \n",
    "                                                      replicates_ids, cpd_replicate_dict)\n",
    "                    if rand_cpds not in replicate_list:\n",
    "                        start_again = False\n",
    "                replicate_list.append(rand_cpds)\n",
    "            if replicate_class not in null_distribution_reps:\n",
    "                null_distribution_reps[replicate_class] = [replicate_list]\n",
    "            else:\n",
    "                null_distribution_reps[replicate_class] += [replicate_list]\n",
    "    \n",
    "    return null_distribution_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_list = list(set(df_level4['dose'].unique().tolist()))[1:7]\n",
    "null_distribution_replicates = get_null_distribution_replicates(cpd_replicate_class_dict, dose_list, \n",
    "                                                                replicates_in_all, cpds_replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(null_distribution, path, file_name):\n",
    "    \"\"\"This function saves the null distribution replicates ids into a pickle file\"\"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    with open(os.path.join(path, file_name), 'wb') as handle:\n",
    "        pickle.dump(null_distribution, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(null_distribution_replicates, L1000_level4_path, 'null_distribution_w.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the null_distribution_moa from pickle\n",
    "with open(os.path.join(L1000_level4_path, 'null_distribution_w.pickle'), 'rb') as handle:\n",
    "    null_distribution_replicates = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_null_distribution(null_distribution_reps, dose_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function assert that each of the list in the 1000 lists of \n",
    "    random replicate combination (per dose) for each cpd size are distinct with no duplicates\n",
    "    \"\"\"\n",
    "    \n",
    "    duplicates_reps = {}\n",
    "    for dose in dose_list:\n",
    "        for keys in null_distribution_reps:\n",
    "            null_dist = null_distribution_reps[keys][dose-1]\n",
    "            for reps in null_dist:\n",
    "                dup_reps = []\n",
    "                new_list = list(filter(lambda x: x != reps, null_dist))\n",
    "                if (len(new_list) != len(null_dist) - 1):\n",
    "                    dup_reps.append(reps)\n",
    "            if dup_reps:\n",
    "                if keys not in duplicates_reps:\n",
    "                    duplicates_reps[keys] = [dup_reps]\n",
    "                else:\n",
    "                    duplicates_reps[keys] += [dup_reps]\n",
    "    return duplicates_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_replicates = assert_null_distribution(null_distribution_replicates, dose_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_replicates ##no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_null_dist_median_scores(df, dose_num, replicate_lists):\n",
    "    \"\"\"\n",
    "    This function calculate the median of the correlation \n",
    "    values for each list in the 1000 lists of random replicate \n",
    "    combination for each no_of_replicate class per dose\n",
    "    \"\"\"\n",
    "    df_dose = df[df['dose'] == dose_num].copy()\n",
    "    df_dose = df_dose.set_index('replicate_id').rename_axis(None, axis=0)\n",
    "    df_dose.drop(['Metadata_broad_sample', 'pert_id', 'dose', 'pert_idose', \n",
    "                  'pert_iname', 'moa', 'sig_id', 'det_plate', 'det_well'], axis = 1, inplace = True)\n",
    "    median_corr_list = []\n",
    "    for rep_list in replicate_lists:\n",
    "        df_reps = df_dose.loc[rep_list].copy()\n",
    "        reps_corr = df_reps.astype('float64').T.corr(method = 'spearman').values\n",
    "        median_corr_val = median(list(reps_corr[np.triu_indices(len(reps_corr), k = 1)]))\n",
    "        median_corr_list.append(median_corr_val)\n",
    "    return median_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_dist_median_scores(null_distribution_cpds, dose_list, df):\n",
    "    \"\"\" \n",
    "    This function calculate the median correlation scores for all \n",
    "    1000 lists of randomly combined compounds for each no_of_replicate class \n",
    "    across all doses (1-6)\n",
    "    \"\"\"\n",
    "    null_distribution_medians = {}\n",
    "    for key in null_distribution_cpds:\n",
    "        median_score_list = []\n",
    "        for dose in dose_list:\n",
    "            replicate_median_scores = calc_null_dist_median_scores(df, dose, null_distribution_cpds[key][dose-1])\n",
    "            median_score_list.append(replicate_median_scores)\n",
    "        null_distribution_medians[key] = median_score_list\n",
    "    return null_distribution_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distribution_medians = get_null_dist_median_scores(null_distribution_replicates, dose_list, df_level4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dose_median_scores(null_dist_medians, dose_list):\n",
    "    \"\"\"\n",
    "    Align median scores per dose, this function return a dictionary, \n",
    "    with keys as dose numbers and values as all median scores for each dose\n",
    "    \"\"\"\n",
    "    median_scores_per_dose = {}\n",
    "    for dose in dose_list:\n",
    "        median_list = []\n",
    "        for keys in null_distribution_medians:\n",
    "            dose_median_list = null_distribution_medians[keys][dose-1]\n",
    "            median_list += dose_median_list\n",
    "        median_scores_per_dose[dose] = median_list\n",
    "    return median_scores_per_dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_null_medians = compute_dose_median_scores(null_distribution_medians, dose_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the null_distribution_medians_per_dose to pickle\n",
    "save_to_pickle(dose_null_medians, L1000_level4_path, 'null_dist_medians_per_dose_w.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A P value can be computed nonparametrically by evaluating the probability of random replicates of different compounds having median similarity value greater than replicates of the same compounds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(median_scores_list, df, dose_name, cpd_name):\n",
    "    \"\"\"\n",
    "    This function calculate the p-value from the \n",
    "    null_distribution median scores for each compound\n",
    "    \"\"\"\n",
    "    actual_med = df.loc[cpd_name, dose_name]\n",
    "    p_value = np.sum(median_scores_list >= actual_med) / len(median_scores_list)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moa_p_vals(null_dist_median, dose_list, df_med_values):\n",
    "    \"\"\"\n",
    "    This function returns a dict, with compounds as the keys and the compound's \n",
    "    p-values for each dose (1-6) as the values\n",
    "    \"\"\"\n",
    "    null_p_vals = {}\n",
    "    for key in null_dist_median:\n",
    "        df_cpd_size = df_med_values[df_med_values['no_of_replicates'] == key]\n",
    "        for cpd in df_cpd_size.index:\n",
    "            dose_p_values = []\n",
    "            for num in dose_list:\n",
    "                dose_name = 'dose_' + str(num)\n",
    "                cpd_p_value = get_p_value(null_dist_median[key][num-1], df_cpd_size, dose_name, cpd)\n",
    "                dose_p_values.append(cpd_p_value)\n",
    "            null_p_vals[cpd] = dose_p_values\n",
    "    sorted_null_p_vals = {key:value for key, value in sorted(null_p_vals.items(), key=lambda item: item[0])}\n",
    "    return sorted_null_p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_p_vals = get_moa_p_vals(null_distribution_medians, dose_list, df_cpd_med_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_p_vals = pd.DataFrame.from_dict(null_p_vals, orient='index', columns = ['dose_' + str(x) for x in dose_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_p_vals['no_of_replicates'] = df_cpd_med_scores['no_of_replicates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dose_1</th>\n",
       "      <th>dose_2</th>\n",
       "      <th>dose_3</th>\n",
       "      <th>dose_4</th>\n",
       "      <th>dose_5</th>\n",
       "      <th>dose_6</th>\n",
       "      <th>no_of_replicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17-hydroxyprogesterone-caproate</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.121</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-iminobiotin</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.618</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-amino-benzamide</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-deazaadenosine</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT-737</th>\n",
       "      <td>0.165</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AICA-ribonucleotide</th>\n",
       "      <td>0.187</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.032</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AKT-inhibitor-1-2</th>\n",
       "      <td>0.586</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.537</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALX-5407</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS-605240</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT-7519</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dose_1  dose_2  dose_3  dose_4  dose_5  \\\n",
       "17-hydroxyprogesterone-caproate   0.921   0.113   0.042   0.000   0.013   \n",
       "2-iminobiotin                     0.899   0.014   0.549   0.762   0.100   \n",
       "3-amino-benzamide                 0.009   0.327   0.400   0.502   0.196   \n",
       "3-deazaadenosine                  0.224   0.521   0.325   0.224   0.505   \n",
       "ABT-737                           0.165   0.904   0.101   0.403   0.048   \n",
       "AICA-ribonucleotide               0.187   0.059   0.345   0.015   0.362   \n",
       "AKT-inhibitor-1-2                 0.586   0.050   0.096   0.088   0.530   \n",
       "ALX-5407                          0.036   0.111   0.003   0.088   0.129   \n",
       "AS-605240                         0.972   0.033   0.841   0.810   0.033   \n",
       "AT-7519                           0.002   0.197   0.043   0.000   0.000   \n",
       "\n",
       "                                 dose_6  no_of_replicates  \n",
       "17-hydroxyprogesterone-caproate   0.121                 3  \n",
       "2-iminobiotin                     0.618                 2  \n",
       "3-amino-benzamide                 0.009                 3  \n",
       "3-deazaadenosine                  0.300                 2  \n",
       "ABT-737                           0.002                 3  \n",
       "AICA-ribonucleotide               0.032                 3  \n",
       "AKT-inhibitor-1-2                 0.537                 3  \n",
       "ALX-5407                          0.010                 3  \n",
       "AS-605240                         0.077                 2  \n",
       "AT-7519                           0.000                 3  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null_p_vals.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, path, file_name):\n",
    "    \"\"\"saves dataframes to csv\"\"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    df.to_csv(os.path.join(path, file_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(df_null_p_vals.reset_index().rename({'index':'cpd'}, axis = 1), L1000_level4_path, \n",
    "            'cpd_replicate_p_values_w.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
