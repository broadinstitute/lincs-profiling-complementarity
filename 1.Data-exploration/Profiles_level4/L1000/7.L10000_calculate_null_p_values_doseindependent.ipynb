{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Null Distribution\n",
    "\n",
    "Code modified from @adeboyeML\n",
    "\n",
    "Null distribution - is generated by getting the median correlation score of randomly combined replicates that do not come from the same compounds.\n",
    "\n",
    "### The goal here: \n",
    "\n",
    "-- is to compute the **p-value** for each compound per dose by evaluating the probability of random combinations of replicates (from different compounds) having greater median correlation score than replicates that come from the same compound.\n",
    "\n",
    "- In our case, we generated 1000 median correlation scores from randomly combined replicates as the **null distribution** for each no_of_replicates/replicate class - we have 1000 medians scores from randomly combined replicates of different compounds.\n",
    "\n",
    "**no_of_replicate** is the number of replicates in a specific compound and **no_of_replicate class** is a specific group of compounds that have the same amount of replicates e.g all compounds with 3 replicates in them are in the same no_of_replicates class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from os import walk\n",
    "from collections import Counter\n",
    "import random\n",
    "import shutil\n",
    "from statistics import median\n",
    "import cmapPy.pandasGEXpress.parse_gct as pg\n",
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1327\n"
     ]
    }
   ],
   "source": [
    "# Load common compounds\n",
    "common_file = pathlib.Path(\n",
    "    \"..\", \"..\", \"..\", \"6.paper_figures\", \"data\", \"significant_compounds_by_threshold_both_assays.tsv.gz\"\n",
    ")\n",
    "common_df = pd.read_csv(common_file, sep=\"\\t\")\n",
    "\n",
    "common_compounds = common_df.compound.unique()\n",
    "print(len(common_compounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load in Level 4 Datasets generated from `calculate_median_scores_notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run either using \"W\" or \"\"\n",
    "# Representing \"whitened\" (aka \"spherized\") L1000 data or not\n",
    "l1000_file_indicator = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1000_level4_path = \"L1000_lvl4_cpd_replicate_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27837, 988)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replicate_id</th>\n",
       "      <th>200814_at</th>\n",
       "      <th>222103_at</th>\n",
       "      <th>201453_x_at</th>\n",
       "      <th>204131_s_at</th>\n",
       "      <th>200059_s_at</th>\n",
       "      <th>205067_at</th>\n",
       "      <th>213702_x_at</th>\n",
       "      <th>214435_x_at</th>\n",
       "      <th>201334_s_at</th>\n",
       "      <th>...</th>\n",
       "      <th>205379_at</th>\n",
       "      <th>sig_id</th>\n",
       "      <th>pert_id</th>\n",
       "      <th>pert_idose</th>\n",
       "      <th>det_plate</th>\n",
       "      <th>det_well</th>\n",
       "      <th>dose</th>\n",
       "      <th>Metadata_broad_sample</th>\n",
       "      <th>pert_iname</th>\n",
       "      <th>moa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REP.A001_A549_24H_X1_B27:A03</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>-0.4940</td>\n",
       "      <td>-0.1721</td>\n",
       "      <td>-0.0339</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>1.8263</td>\n",
       "      <td>-0.1316</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>-0.4660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>REP.A001_A549_24H:A03</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>-666</td>\n",
       "      <td>REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...</td>\n",
       "      <td>A03</td>\n",
       "      <td>0</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>Control vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REP.A001_A549_24H_X2_B27:A03</td>\n",
       "      <td>-0.0447</td>\n",
       "      <td>-1.6390</td>\n",
       "      <td>-0.5276</td>\n",
       "      <td>-0.5092</td>\n",
       "      <td>-0.5733</td>\n",
       "      <td>0.2445</td>\n",
       "      <td>0.6159</td>\n",
       "      <td>-1.1273</td>\n",
       "      <td>2.8250</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.5836</td>\n",
       "      <td>REP.A001_A549_24H:A03</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>-666</td>\n",
       "      <td>REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...</td>\n",
       "      <td>A03</td>\n",
       "      <td>0</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>Control vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REP.A001_A549_24H_X3_B27:A03</td>\n",
       "      <td>-0.9583</td>\n",
       "      <td>0.2657</td>\n",
       "      <td>-0.8204</td>\n",
       "      <td>-0.5851</td>\n",
       "      <td>-2.0808</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>-0.0497</td>\n",
       "      <td>-0.3012</td>\n",
       "      <td>-0.9787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1416</td>\n",
       "      <td>REP.A001_A549_24H:A03</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>-666</td>\n",
       "      <td>REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...</td>\n",
       "      <td>A03</td>\n",
       "      <td>0</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>Control vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REP.A001_A549_24H_X1_B27:A04</td>\n",
       "      <td>-0.2130</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>-0.8768</td>\n",
       "      <td>-0.6968</td>\n",
       "      <td>-1.7018</td>\n",
       "      <td>-0.3779</td>\n",
       "      <td>-0.6745</td>\n",
       "      <td>-1.9799</td>\n",
       "      <td>-1.1429</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.8243</td>\n",
       "      <td>REP.A001_A549_24H:A04</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>-666</td>\n",
       "      <td>REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...</td>\n",
       "      <td>A04</td>\n",
       "      <td>0</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>Control vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REP.A001_A549_24H_X2_B27:A04</td>\n",
       "      <td>0.7499</td>\n",
       "      <td>-1.2819</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>1.7090</td>\n",
       "      <td>1.6765</td>\n",
       "      <td>-1.2690</td>\n",
       "      <td>1.7974</td>\n",
       "      <td>-1.2213</td>\n",
       "      <td>3.4625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3157</td>\n",
       "      <td>REP.A001_A549_24H:A04</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>-666</td>\n",
       "      <td>REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...</td>\n",
       "      <td>A04</td>\n",
       "      <td>0</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>Control vehicle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 988 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   replicate_id  200814_at  222103_at  201453_x_at  \\\n",
       "0  REP.A001_A549_24H_X1_B27:A03     0.3547    -0.4940      -0.1721   \n",
       "1  REP.A001_A549_24H_X2_B27:A03    -0.0447    -1.6390      -0.5276   \n",
       "2  REP.A001_A549_24H_X3_B27:A03    -0.9583     0.2657      -0.8204   \n",
       "3  REP.A001_A549_24H_X1_B27:A04    -0.2130     0.4931      -0.8768   \n",
       "4  REP.A001_A549_24H_X2_B27:A04     0.7499    -1.2819       0.4981   \n",
       "\n",
       "   204131_s_at  200059_s_at  205067_at  213702_x_at  214435_x_at  201334_s_at  \\\n",
       "0      -0.0339      -0.4355     1.8263      -0.1316       0.0853      -0.4660   \n",
       "1      -0.5092      -0.5733     0.2445       0.6159      -1.1273       2.8250   \n",
       "2      -0.5851      -2.0808     0.0739      -0.0497      -0.3012      -0.9787   \n",
       "3      -0.6968      -1.7018    -0.3779      -0.6745      -1.9799      -1.1429   \n",
       "4       1.7090       1.6765    -1.2690       1.7974      -1.2213       3.4625   \n",
       "\n",
       "   ...  205379_at                 sig_id  pert_id  pert_idose  \\\n",
       "0  ...     0.1046  REP.A001_A549_24H:A03     DMSO        -666   \n",
       "1  ...    -1.5836  REP.A001_A549_24H:A03     DMSO        -666   \n",
       "2  ...    -0.1416  REP.A001_A549_24H:A03     DMSO        -666   \n",
       "3  ...    -1.8243  REP.A001_A549_24H:A04     DMSO        -666   \n",
       "4  ...     0.3157  REP.A001_A549_24H:A04     DMSO        -666   \n",
       "\n",
       "                                           det_plate  det_well  dose  \\\n",
       "0  REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...       A03     0   \n",
       "1  REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...       A03     0   \n",
       "2  REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...       A03     0   \n",
       "3  REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...       A04     0   \n",
       "4  REP.A001_A549_24H_X1_B27|REP.A001_A549_24H_X2_...       A04     0   \n",
       "\n",
       "   Metadata_broad_sample  pert_iname              moa  \n",
       "0                   DMSO        DMSO  Control vehicle  \n",
       "1                   DMSO        DMSO  Control vehicle  \n",
       "2                   DMSO        DMSO  Control vehicle  \n",
       "3                   DMSO        DMSO  Control vehicle  \n",
       "4                   DMSO        DMSO  Control vehicle  \n",
       "\n",
       "[5 rows x 988 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_level4 = pd.read_csv(\n",
    "    os.path.join(L1000_level4_path, f'L1000_level4{l1000_file_indicator}_cpd_replicates.csv.gz'), \n",
    "    compression='gzip',\n",
    "    low_memory = False\n",
    ")\n",
    "print(df_level4.shape)\n",
    "df_level4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dose_1</th>\n",
       "      <th>dose_2</th>\n",
       "      <th>dose_3</th>\n",
       "      <th>dose_4</th>\n",
       "      <th>dose_5</th>\n",
       "      <th>dose_6</th>\n",
       "      <th>no_of_replicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17-hydroxyprogesterone-caproate</th>\n",
       "      <td>0.073370</td>\n",
       "      <td>0.064999</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.149151</td>\n",
       "      <td>0.031656</td>\n",
       "      <td>0.226888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-iminobiotin</th>\n",
       "      <td>0.085434</td>\n",
       "      <td>0.196718</td>\n",
       "      <td>0.012828</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.046477</td>\n",
       "      <td>0.128650</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-amino-benzamide</th>\n",
       "      <td>0.011228</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.052259</td>\n",
       "      <td>0.013569</td>\n",
       "      <td>-0.013665</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-deazaadenosine</th>\n",
       "      <td>0.068822</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.045240</td>\n",
       "      <td>0.204147</td>\n",
       "      <td>0.061483</td>\n",
       "      <td>0.049968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacavir</th>\n",
       "      <td>0.055853</td>\n",
       "      <td>0.047647</td>\n",
       "      <td>0.170106</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>0.033011</td>\n",
       "      <td>0.080949</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   dose_1    dose_2    dose_3    dose_4  \\\n",
       "17-hydroxyprogesterone-caproate  0.073370  0.064999  0.022398  0.149151   \n",
       "2-iminobiotin                    0.085434  0.196718  0.012828  0.005784   \n",
       "3-amino-benzamide                0.011228 -0.000293  0.052259  0.013569   \n",
       "3-deazaadenosine                 0.068822  0.001870  0.045240  0.204147   \n",
       "abacavir                         0.055853  0.047647  0.170106  0.071078   \n",
       "\n",
       "                                   dose_5    dose_6  no_of_replicates  \n",
       "17-hydroxyprogesterone-caproate  0.031656  0.226888                 3  \n",
       "2-iminobiotin                    0.046477  0.128650                 2  \n",
       "3-amino-benzamide               -0.013665  0.021126                 3  \n",
       "3-deazaadenosine                 0.061483  0.049968                 2  \n",
       "abacavir                         0.033011  0.080949                 3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load compound median scores\n",
    "if l1000_file_indicator == \"W\":\n",
    "    file = os.path.join(L1000_level4_path, 'cpd_replicate_median_scores_w.csv')\n",
    "else:\n",
    "    file = os.path.join(L1000_level4_path, 'cpd_replicate_median_scores.csv')\n",
    "\n",
    "df_cpd_med_scores = pd.read_csv(file)\n",
    "df_cpd_med_scores = df_cpd_med_scores.set_index('cpd').rename_axis(None, axis=0).copy()\n",
    "\n",
    "# Subset to common compound measurements\n",
    "df_cpd_med_scores = df_cpd_med_scores.loc[df_cpd_med_scores.index.isin(common_compounds), :]\n",
    "\n",
    "print(df_cpd_med_scores.shape)\n",
    "df_cpd_med_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpds_replicates(df, df_lvl4):\n",
    "    \"\"\"\n",
    "    This function returns all replicates id/names found in each compound\n",
    "    \"\"\"\n",
    "        \n",
    "    replicates_in_all = []\n",
    "    cpds_replicates = {}\n",
    "    for cpd in df.index.unique():\n",
    "        replicate_names = df_lvl4[df_lvl4['pert_iname'] == cpd]['replicate_id'].values.tolist()\n",
    "        replicates_in_all += replicate_names\n",
    "        cpds_replicates[cpd] = replicate_names\n",
    "        \n",
    "    return replicates_in_all, cpds_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicates_in_all, cpds_replicates = get_cpds_replicates(df_cpd_med_scores, df_level4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replicates_classes(df, df_lvl4, cpds_replicates):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function gets all replicates ids for each distinct \n",
    "    no_of_replicates (i.e. number of replicates per cpd) class\n",
    "    \n",
    "    Returns replicate_class_dict dictionary, with no_of_replicate classes as the keys, \n",
    "    and all the replicate_ids for each no_of_replicate class as the values\n",
    "    \"\"\"\n",
    "    \n",
    "    df['replicate_id'] = list(cpds_replicates.values())\n",
    "    replicate_class_dict = {}\n",
    "    for size in df['no_of_replicates'].unique():\n",
    "        rep_lists = []\n",
    "        for idx in range(df[df['no_of_replicates'] == size].shape[0]):\n",
    "            rep_ids = df[df['no_of_replicates'] == size]['replicate_id'].values.tolist()[idx]\n",
    "            rep_lists += rep_ids\n",
    "            replicate_class_dict[size] = rep_lists\n",
    "                \n",
    "    return replicate_class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_replicate_class_dict = get_replicates_classes(df_cpd_med_scores, df_level4, cpds_replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 2, 4, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpd_replicate_class_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similar_replicates(replicates, cpd_dict):\n",
    "    \"\"\"This function checks if two replicates are of the same compounds\"\"\"\n",
    "    \n",
    "    for x in range(len(replicates)):\n",
    "        for y in range(x+1, len(replicates)):\n",
    "            for kys in cpd_dict:\n",
    "                if all(i in cpd_dict[kys] for i in [replicates[x], replicates[y]]):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_replicates(all_replicates, no_of_replicates, replicates_ids, cpd_replicate_dict):\n",
    "    \"\"\"\n",
    "    This function return a list of random replicates that are not of the same compounds\n",
    "    or found in the current cpd's size list\n",
    "    \"\"\"\n",
    "    while (True):\n",
    "        random_replicates = random.sample(all_replicates, no_of_replicates)\n",
    "        if not (any(rep in replicates_ids for rep in random_replicates) & \n",
    "                (check_similar_replicates(random_replicates, cpd_replicate_dict))):\n",
    "            break\n",
    "    return random_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_distribution_replicates(\n",
    "    cpd_replicate_class_dict,\n",
    "    replicates_lists,\n",
    "    cpd_replicate_dict,\n",
    "    rand_num = 1000\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns a null distribution dictionary, with no_of_replicates(replicate class) \n",
    "    as the keys and 1000 lists of randomly selected replicate combinations as the values\n",
    "    for each no_of_replicates class\n",
    "    \"\"\"\n",
    "    random.seed(1903)\n",
    "    null_distribution_reps = {}\n",
    "    for replicate_class in cpd_replicate_class_dict:\n",
    "        replicates_ids = cpd_replicate_class_dict[replicate_class]\n",
    "        replicate_list = []\n",
    "        for idx in range(rand_num):\n",
    "            start_again = True\n",
    "            while (start_again):\n",
    "                rand_cpds = get_random_replicates(\n",
    "                    replicates_lists,\n",
    "                    replicate_class,\n",
    "                    replicates_ids,\n",
    "                    cpd_replicate_dict\n",
    "                )\n",
    "                if rand_cpds not in replicate_list:\n",
    "                    start_again = False\n",
    "            replicate_list.append(rand_cpds)\n",
    "        null_distribution_reps[replicate_class] = replicate_list\n",
    "    \n",
    "    return null_distribution_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cpds_replicates.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distribution_replicates = get_null_distribution_replicates(\n",
    "    cpd_replicate_class_dict,\n",
    "    replicates_in_all,\n",
    "    cpds_replicates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(null_distribution, path, file_name):\n",
    "    \"\"\"This function saves the null distribution replicates ids into a pickle file\"\"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    with open(os.path.join(path, file_name), 'wb') as handle:\n",
    "        pickle.dump(null_distribution, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "if l1000_file_indicator == \"W\":\n",
    "    file = 'null_distribution_w_dose_independent.pickle'\n",
    "else:\n",
    "    file = 'null_distribution_dose_independent.pickle'\n",
    "\n",
    "save_to_pickle(null_distribution_replicates, L1000_level4_path, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the null_distribution_moa from pickle\n",
    "with open(os.path.join(L1000_level4_path, file), 'rb') as handle:\n",
    "    null_distribution_replicates = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_null_distribution(null_distribution_reps):\n",
    "    \"\"\"\n",
    "    This function assert that each of the list in the 1000 lists of random replicate \n",
    "    combination for each no_of_replicate class are distinct with no duplicates\n",
    "    \"\"\"\n",
    "    duplicates_reps = {}\n",
    "    for keys in null_distribution_reps:\n",
    "        null_dist = null_distribution_reps[keys]\n",
    "        for reps in null_dist:\n",
    "            dup_reps = []\n",
    "            new_list = list(filter(lambda x: x != reps, null_dist))\n",
    "            if (len(new_list) != len(null_dist) - 1):\n",
    "                dup_reps.append(reps)\n",
    "        if dup_reps:\n",
    "            if keys not in duplicates_reps:\n",
    "                duplicates_reps[keys] = [dup_reps]\n",
    "            else:\n",
    "                duplicates_reps[keys] += [dup_reps]\n",
    "    return duplicates_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_replicates = assert_null_distribution(null_distribution_replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_replicates ##no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_null_dist_median_scores(df, replicate_lists):\n",
    "    \"\"\"\n",
    "    This function calculate the median of the correlation \n",
    "    values for each list in the 1000 lists of random replicate \n",
    "    combination for each no_of_replicate class per dose\n",
    "    \"\"\"\n",
    "    df = df.set_index('replicate_id').rename_axis(None, axis=0)\n",
    "    df.drop(['Metadata_broad_sample', 'pert_id', 'dose', 'pert_idose', \n",
    "             'pert_iname', 'moa', 'sig_id', 'det_plate', 'det_well'], axis = 1, inplace = True)\n",
    "    median_corr_list = []\n",
    "    for rep_list in replicate_lists:\n",
    "        df_reps = df.loc[rep_list].copy()\n",
    "        reps_corr = df_reps.astype('float64').T.corr(method = 'spearman').values\n",
    "        median_corr_val = median(list(reps_corr[np.triu_indices(len(reps_corr), k = 1)]))\n",
    "        median_corr_list.append(median_corr_val)\n",
    "    return median_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_dist_median_scores(null_distribution_cpds, df):\n",
    "    \"\"\" \n",
    "    This function calculate the median correlation scores for all \n",
    "    1000 lists of randomly combined compounds for each no_of_replicate class \n",
    "    \"\"\"\n",
    "    null_distribution_medians = {}\n",
    "    for key in null_distribution_cpds:\n",
    "        replicate_median_scores = calc_null_dist_median_scores(df, null_distribution_cpds[key])\n",
    "        null_distribution_medians[key] = replicate_median_scores\n",
    "    return null_distribution_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distribution_medians = get_null_dist_median_scores(null_distribution_replicates, df_level4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dose_median_scores(null_dist_medians, dose_list):\n",
    "    \"\"\"\n",
    "    This function align median scores per dose, and return a dictionary, \n",
    "    with keys as dose numbers and values as all median null distribution/non-replicate correlation \n",
    "    scores for each dose\n",
    "    \"\"\"\n",
    "    median_scores_per_dose = {}\n",
    "    for dose in dose_list:\n",
    "        median_list = []\n",
    "        for keys in null_distribution_medians:\n",
    "            dose_median_list = null_distribution_medians[keys]\n",
    "            median_list += dose_median_list\n",
    "        median_scores_per_dose[dose] = median_list\n",
    "    return median_scores_per_dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dose_list only to index in median_score data\n",
    "dose_list = list(set(df_level4['dose'].unique().tolist()))[1:7]\n",
    "\n",
    "dose_null_medians = compute_dose_median_scores(null_distribution_medians, dose_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the null_distribution_medians_per_dose to pickle\n",
    "if l1000_file_indicator == \"W\":\n",
    "    file = 'null_dist_medians_per_dose_w_dose_independent.pickle'\n",
    "else:\n",
    "    file = 'null_dist_medians_per_dose_dose_independent.pickle'\n",
    "\n",
    "    save_to_pickle(dose_null_medians, L1000_level4_path, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A P value can be computed nonparametrically by evaluating the probability of random replicates of different compounds having median similarity value greater than replicates of the same compounds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(median_scores_list, df, dose_name, cpd_name):\n",
    "    \"\"\"\n",
    "    This function calculate the p-value from the \n",
    "    null_distribution median scores for each compound\n",
    "    \"\"\"\n",
    "    actual_med = df.loc[cpd_name, dose_name]\n",
    "    p_value = np.sum(median_scores_list >= actual_med) / len(median_scores_list)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moa_p_vals(null_dist_median, dose_list, df_med_values):\n",
    "    \"\"\"\n",
    "    This function returns a dict, with compounds as the keys and the compound's \n",
    "    p-values as the values\n",
    "    \"\"\"\n",
    "    null_p_vals = {}\n",
    "    for key in null_dist_median:\n",
    "        df_replicate_class = df_med_values[df_med_values['no_of_replicates'] == key]\n",
    "        for cpd in df_replicate_class.index:\n",
    "            dose_p_values = []\n",
    "            for num in dose_list:\n",
    "                dose_name = 'dose_' + str(num)\n",
    "                cpd_p_value = get_p_value(null_dist_median[key], df_replicate_class, dose_name, cpd)\n",
    "                dose_p_values.append(cpd_p_value)\n",
    "            null_p_vals[cpd] = dose_p_values\n",
    "    sorted_null_p_vals = {key:value for key, value in sorted(null_p_vals.items(), key=lambda item: item[0])}\n",
    "    return sorted_null_p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_p_vals = get_moa_p_vals(null_distribution_medians, dose_list, df_cpd_med_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_p_vals = pd.DataFrame.from_dict(null_p_vals, orient='index', columns = ['dose_' + str(x) for x in dose_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_p_vals['no_of_replicates'] = df_cpd_med_scores['no_of_replicates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dose_1</th>\n",
       "      <th>dose_2</th>\n",
       "      <th>dose_3</th>\n",
       "      <th>dose_4</th>\n",
       "      <th>dose_5</th>\n",
       "      <th>dose_6</th>\n",
       "      <th>no_of_replicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17-hydroxyprogesterone-caproate</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-iminobiotin</th>\n",
       "      <td>0.147</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.076</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-amino-benzamide</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.295</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-deazaadenosine</th>\n",
       "      <td>0.198</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.252</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacavir</th>\n",
       "      <td>0.124</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.068</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abiraterone-acetate</th>\n",
       "      <td>0.386</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.125</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abt-202</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.120</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abt-239</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abt-724</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acarbose</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dose_1  dose_2  dose_3  dose_4  dose_5  \\\n",
       "17-hydroxyprogesterone-caproate   0.080   0.104   0.287   0.002   0.228   \n",
       "2-iminobiotin                     0.147   0.028   0.414   0.454   0.266   \n",
       "3-amino-benzamide                 0.350   0.443   0.133   0.335   0.557   \n",
       "3-deazaadenosine                  0.198   0.473   0.269   0.025   0.216   \n",
       "abacavir                          0.124   0.154   0.002   0.086   0.224   \n",
       "abiraterone-acetate               0.386   0.015   0.375   0.033   0.319   \n",
       "abt-202                           0.660   0.107   0.550   0.172   0.814   \n",
       "abt-239                           0.044   0.067   0.048   0.266   0.273   \n",
       "abt-724                           0.191   0.025   0.111   0.262   0.230   \n",
       "acarbose                          0.395   0.256   0.067   0.002   0.246   \n",
       "\n",
       "                                 dose_6  no_of_replicates  \n",
       "17-hydroxyprogesterone-caproate   0.001                 3  \n",
       "2-iminobiotin                     0.076                 2  \n",
       "3-amino-benzamide                 0.295                 3  \n",
       "3-deazaadenosine                  0.252                 2  \n",
       "abacavir                          0.068                 3  \n",
       "abiraterone-acetate               0.125                 3  \n",
       "abt-202                           0.120                 3  \n",
       "abt-239                           0.001                 3  \n",
       "abt-724                           0.001                 3  \n",
       "acarbose                          0.064                 3  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null_p_vals.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, path, file_name):\n",
    "    \"\"\"saves dataframes to csv\"\"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    df.to_csv(os.path.join(path, file_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the null_distribution_medians_per_dose to pickle\n",
    "if l1000_file_indicator == \"W\":\n",
    "    file = 'cpd_replicate_p_values_w_dose_independent.csv'\n",
    "else:\n",
    "    file = 'cpd_replicate_p_values_dose_independent.csv'\n",
    "\n",
    "save_to_csv(df_null_p_vals.reset_index().rename({'index':'cpd'}, axis = 1), L1000_level4_path, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7548, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>no_of_replicates</th>\n",
       "      <th>dose</th>\n",
       "      <th>p_value</th>\n",
       "      <th>matching_score</th>\n",
       "      <th>assay</th>\n",
       "      <th>normalization</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17-hydroxyprogesterone-caproate</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04 uM</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.073370</td>\n",
       "      <td>L1000</td>\n",
       "      <td>non_spherized</td>\n",
       "      <td>all_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-iminobiotin</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04 uM</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.085434</td>\n",
       "      <td>L1000</td>\n",
       "      <td>non_spherized</td>\n",
       "      <td>all_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-amino-benzamide</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04 uM</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>L1000</td>\n",
       "      <td>non_spherized</td>\n",
       "      <td>all_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-deazaadenosine</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04 uM</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.068822</td>\n",
       "      <td>L1000</td>\n",
       "      <td>non_spherized</td>\n",
       "      <td>all_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abacavir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04 uM</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.055853</td>\n",
       "      <td>L1000</td>\n",
       "      <td>non_spherized</td>\n",
       "      <td>all_data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          compound  no_of_replicates     dose  p_value  \\\n",
       "0  17-hydroxyprogesterone-caproate                 3  0.04 uM    0.080   \n",
       "1                    2-iminobiotin                 2  0.04 uM    0.147   \n",
       "2                3-amino-benzamide                 3  0.04 uM    0.350   \n",
       "3                 3-deazaadenosine                 2  0.04 uM    0.198   \n",
       "4                         abacavir                 3  0.04 uM    0.124   \n",
       "\n",
       "   matching_score  assay  normalization  category  \n",
       "0        0.073370  L1000  non_spherized  all_data  \n",
       "1        0.085434  L1000  non_spherized  all_data  \n",
       "2        0.011228  L1000  non_spherized  all_data  \n",
       "3        0.068822  L1000  non_spherized  all_data  \n",
       "4        0.055853  L1000  non_spherized  all_data  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if l1000_file_indicator == \"W\":\n",
    "    cpd_summary_file = pathlib.Path(L1000_level4_path, 'cpd_replicate_p_values_melted_w_dose_independent.csv')\n",
    "    input_data = \"spherized\"\n",
    "else:\n",
    "    cpd_summary_file = pathlib.Path(L1000_level4_path, 'cpd_replicate_p_values_melted_dose_independent.csv')\n",
    "    input_data = \"non_spherized\"\n",
    "\n",
    "\n",
    "dose_recode_info = {\n",
    "    'dose_1': '0.04 uM', 'dose_2':'0.12 uM', 'dose_3':'0.37 uM',\n",
    "    'dose_4': '1.11 uM', 'dose_5':'3.33 uM', 'dose_6':'10 uM'\n",
    "}\n",
    "\n",
    "# Melt the p values\n",
    "cpd_score_summary_pval_df = (\n",
    "    df_null_p_vals\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"compound\"})\n",
    "    .melt(\n",
    "        id_vars=[\"compound\", \"no_of_replicates\"],\n",
    "        value_vars=[\"dose_1\", \"dose_2\", \"dose_3\", \"dose_4\", \"dose_5\", \"dose_6\"],\n",
    "        var_name=\"dose\",\n",
    "        value_name=\"p_value\"\n",
    "    )\n",
    ")\n",
    "\n",
    "cpd_score_summary_pval_df.dose = cpd_score_summary_pval_df.dose.replace(dose_recode_info)\n",
    "\n",
    "# Melt the median matching scores\n",
    "cpd_score_summary_df = (\n",
    "    df_cpd_med_scores\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"compound\"})\n",
    "    .melt(\n",
    "        id_vars=[\"compound\", \"no_of_replicates\"],\n",
    "        value_vars=[\"dose_1\", \"dose_2\", \"dose_3\", \"dose_4\", \"dose_5\", \"dose_6\"],\n",
    "        var_name=\"dose\",\n",
    "        value_name=\"matching_score\"\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "cpd_score_summary_df.dose = cpd_score_summary_df.dose.replace(dose_recode_info)\n",
    "\n",
    "summary_df = (\n",
    "    cpd_score_summary_pval_df\n",
    "    .merge(cpd_score_summary_df, on=[\"compound\", \"no_of_replicates\", \"dose\"], how=\"inner\")\n",
    "    .assign(\n",
    "        assay=\"L1000\",\n",
    "        normalization=input_data,\n",
    "        category=\"all_data\"\n",
    "    )\n",
    ")\n",
    "\n",
    "summary_df.to_csv(cpd_summary_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(summary_df.shape)\n",
    "summary_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lincs-complimentarity]",
   "language": "python",
   "name": "conda-env-lincs-complimentarity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
